{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = {}\n",
    "    for index in range(3):\n",
    "        X_train = pd.read_csv('Xtr%s_mat50.csv' % index, delimiter=' ', names=range(0,50)).values\n",
    "        seq_train = pd.read_csv('Xtr%s.csv' % index, names='1').values\n",
    "        X_test = pd.read_csv('Xte%s_mat50.csv' % index, delimiter=' ', names=range(0,50)).values\n",
    "        seq_test = pd.read_csv('Xte%s.csv' % index, names='1').values\n",
    "        labels = pd.read_csv('Ytr%s.csv' % index, names=('Id', 'Bound'), skiprows=[0], delimiter=',')\n",
    "\n",
    "        data[index] = {\n",
    "            'seq_train': seq_train,\n",
    "            'X_train': X_train,\n",
    "            'y_train': labels['Bound'].values,\n",
    "            'seq_test': seq_test,\n",
    "            'X_test': X_test,\n",
    "            'ids': labels['Id'].values,\n",
    "        }\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manipulation import split_train_test_valid, get_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel ridge regression (linear kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ridge_regression import get_ridge_prediction, kernel_ridge_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = load_data()\n",
    "\n",
    "train_X, train_y, test_X, test_y, valid_X, valid_y = split_train_test_valid(DATA[0]['X_train'], DATA[0]['y_train'])\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_K(x1, x2):\n",
    "    return x1 @ x2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_PARAMS_SPAN = [10**i for i in range(-10, 10)] + [10**i/2 for i in range(-10, 10)]\n",
    "\n",
    "def get_best_reg_param():\n",
    "    test_precisions = []\n",
    "    for reg in REG_PARAMS_SPAN:\n",
    "        alpha = kernel_ridge_regression(linear_K, train_X, train_y, reg)\n",
    "        pred = get_ridge_prediction(linear_K, train_X, test_X, alpha)\n",
    "        test_precisions.append(get_precision(pred, test_y))\n",
    "        \n",
    "    best_reg_index = max(range(len(REG_PARAMS_SPAN)), key=lambda x: test_precisions[x])\n",
    "    return REG_PARAMS_SPAN[best_reg_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_param = get_best_reg_param()\n",
    "alpha = kernel_ridge_regression(linear_K, train_X, train_y, reg_param)\n",
    "pred = get_ridge_prediction(linear_K, train_X, valid_X, alpha)\n",
    "get_precision(pred, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Linear Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVM import a_compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_train(kernel, X, y, Lambda):\n",
    "    N = y.shape[0]\n",
    "    y = 2*y-1\n",
    "    \n",
    "    K = kernel(X,X)\n",
    "    alpha = np.zeros(N)\n",
    "    # we assume K is of size N,N\n",
    "    value = 100000\n",
    "\n",
    "    for n in range(1,100):\n",
    "        gradient = K @ alpha - y\n",
    "        potential_alpha = alpha - 1/n * gradient\n",
    "        for i in range(N):\n",
    "            if potential_alpha[i] * y[i] > 1. / (2. * Lambda * N):\n",
    "                potential_alpha[i] = (1. / (2. * Lambda * N))\n",
    "            if potential_alpha[i] * y[i] < 0.:\n",
    "                potential_alpha[i] = 0.\n",
    "        alpha = potential_alpha\n",
    "\n",
    "    return alpha\n",
    "\n",
    "def SVM_predict(X_train, X_test, alpha):\n",
    "    pos_neg = np.sign(alpha @ linear_K(train_X, test_X))\n",
    "    print(pos_neg)\n",
    "    return (pos_neg/2+0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00416667,  0.00416667,  0.        , ...,  0.00416667,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = linear_K(train_X, train_X)\n",
    "alpha = SVM_train(linear_K, train_X, train_y, 0.1)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05709082,  0.05511874,  0.05492872,  0.06023797,  0.05724638,\n",
       "        0.05634206,  0.05595266,  0.05648728,  0.05314026,  0.05368915,\n",
       "        0.05871584,  0.05477562,  0.05104019,  0.0562308 ,  0.05624458,\n",
       "        0.05596448,  0.053731  ,  0.05580941,  0.05592559,  0.05472885,\n",
       "        0.05585765,  0.05376349,  0.05113372,  0.05624557,  0.05561102,\n",
       "        0.05886303,  0.05459003,  0.05415879,  0.05567305,  0.05258694,\n",
       "        0.05151819,  0.05653897,  0.05713463,  0.05526347,  0.05967677,\n",
       "        0.05455606,  0.05590196,  0.05409922,  0.05543774,  0.05558197,\n",
       "        0.05443693,  0.0525126 ,  0.05682794,  0.05575526,  0.0571622 ,\n",
       "        0.05570603,  0.05536931,  0.05562628,  0.0580611 ,  0.05716515,\n",
       "        0.05539097,  0.05432764,  0.05311417,  0.05846723,  0.05740932,\n",
       "        0.05637258,  0.0550508 ,  0.05547515,  0.0546043 ,  0.05638882,\n",
       "        0.0541327 ,  0.05545349,  0.05324216,  0.05275333,  0.05434438,\n",
       "        0.05417208,  0.05727493,  0.05650894,  0.05540131,  0.05493315,\n",
       "        0.05724736,  0.05729708,  0.05251113,  0.05701008,  0.05352916,\n",
       "        0.05469833,  0.05621554,  0.05591279,  0.0532525 ,  0.05321853,\n",
       "        0.0548918 ,  0.05356953,  0.05507049,  0.05569372,  0.0527809 ,\n",
       "        0.05607918,  0.05214585,  0.05085312,  0.05337951,  0.05700861,\n",
       "        0.05283406,  0.05622539,  0.05642771,  0.05717057,  0.05557016,\n",
       "        0.05285375,  0.05322641,  0.05452111,  0.0548534 ,  0.05012652,\n",
       "        0.05599992,  0.05297928,  0.05618059,  0.05716515,  0.05373887,\n",
       "        0.0526406 ,  0.05526938,  0.05285375,  0.05660641,  0.05727739,\n",
       "        0.0566074 ,  0.05523196,  0.05264306,  0.05359661,  0.05579267,\n",
       "        0.05528858,  0.05257463,  0.05412581,  0.05290741,  0.05615597,\n",
       "        0.0564095 ,  0.05792031,  0.0553378 ,  0.05842342,  0.05340511,\n",
       "        0.05365666,  0.05246239,  0.05511431,  0.05614465,  0.05570357,\n",
       "        0.05580941,  0.05289018,  0.05454818,  0.05868482,  0.05446007,\n",
       "        0.05606244,  0.05321164,  0.05932528,  0.05386293,  0.05782579,\n",
       "        0.05501881,  0.05387819,  0.05776869,  0.05364485,  0.05642771,\n",
       "        0.05531467,  0.05703273,  0.05229994,  0.05022694,  0.05118   ,\n",
       "        0.0547323 ,  0.05883201,  0.05306346,  0.05402686,  0.05650992,\n",
       "        0.05744378,  0.05561988,  0.05268736,  0.0550828 ,  0.05509216,\n",
       "        0.05478349,  0.05441428,  0.05452554,  0.05590688,  0.05691064,\n",
       "        0.05308217,  0.05581089,  0.05505031,  0.0531949 ,  0.05667927,\n",
       "        0.05594232,  0.05709623,  0.05570012,  0.05450831,  0.05560856,\n",
       "        0.05397025,  0.0560078 ,  0.05374134,  0.05518273,  0.05522556,\n",
       "        0.05798529,  0.05312155,  0.05436161,  0.05603684,  0.0553314 ,\n",
       "        0.05598761,  0.05789816,  0.05612447,  0.05352966,  0.05781742,\n",
       "        0.05473673,  0.05721192,  0.0563903 ,  0.05301079,  0.05524722,\n",
       "        0.05648728,  0.05449059,  0.05692344,  0.0555101 ,  0.05538654,\n",
       "        0.05678905,  0.05427841,  0.05140546,  0.05719912,  0.0536035 ,\n",
       "        0.05437293,  0.05487309,  0.05628348,  0.05333865,  0.05515024,\n",
       "        0.053635  ,  0.0520853 ,  0.0523915 ,  0.05582615,  0.05353064,\n",
       "        0.05482042,  0.05453539,  0.05768746,  0.05437096,  0.05360448,\n",
       "        0.05494053,  0.05880346,  0.05391856,  0.05586454,  0.05433355,\n",
       "        0.05490361,  0.05541361,  0.0563204 ,  0.05650205,  0.05823488,\n",
       "        0.05493463,  0.05544955,  0.05368768,  0.05645873,  0.0595852 ,\n",
       "        0.05974864,  0.05257709,  0.05698251,  0.05620225,  0.05431337,\n",
       "        0.05537522,  0.05341545,  0.05741474,  0.05531516,  0.05376349,\n",
       "        0.05556425,  0.05541017,  0.0558739 ,  0.0549297 ,  0.05714103,\n",
       "        0.05657934,  0.05715137,  0.0564858 ,  0.05350159,  0.05476823,\n",
       "        0.05655029,  0.05451372,  0.05599451,  0.05359808,  0.05528414,\n",
       "        0.05456935,  0.05258349,  0.05495038,  0.05373051,  0.05563957,\n",
       "        0.05643214,  0.05525215,  0.05622194,  0.05729708,  0.05486029,\n",
       "        0.05757325,  0.05389788,  0.05625492,  0.05558542,  0.05735714,\n",
       "        0.05479826,  0.05506705,  0.05622489,  0.05206512,  0.05867498,\n",
       "        0.05691507,  0.05178009,  0.05544315,  0.05752205,  0.05811181,\n",
       "        0.05580547,  0.05786567,  0.05559576,  0.05549583,  0.05515714,\n",
       "        0.05303688,  0.05361088,  0.05402046,  0.05558197,  0.05554456,\n",
       "        0.05443939,  0.05734779,  0.0521813 ,  0.05328056,  0.05232455,\n",
       "        0.05562333,  0.0549873 ,  0.05675262,  0.05537325,  0.05386342,\n",
       "        0.05497745,  0.05457132,  0.05544611,  0.05746347,  0.05649269,\n",
       "        0.05739357,  0.05585421,  0.05705193,  0.05239692,  0.05624606,\n",
       "        0.05563711,  0.05304722,  0.05432174,  0.05823488,  0.05372903,\n",
       "        0.05696873,  0.05623572,  0.05554604,  0.05865676,  0.04929161,\n",
       "        0.05603044,  0.05533436,  0.05581285,  0.05490213,  0.05555047,\n",
       "        0.0549105 ,  0.05601469,  0.05717204,  0.05604767,  0.05562185,\n",
       "        0.05120609,  0.05085755,  0.05662364,  0.05585962,  0.05776278,\n",
       "        0.05719813,  0.05534371,  0.05579415,  0.05298519,  0.05434389,\n",
       "        0.05470473,  0.05444628,  0.05571588,  0.05485389,  0.05491887,\n",
       "        0.0529015 ,  0.05804633,  0.05564696,  0.05529202,  0.05572474,\n",
       "        0.05735616,  0.05499468,  0.05297042,  0.05465895,  0.05454425,\n",
       "        0.05617567,  0.05327318,  0.05399141,  0.05229403,  0.0546112 ,\n",
       "        0.05514483,  0.05601814,  0.05356067,  0.05307528,  0.05635387,\n",
       "        0.05254854,  0.055166  ,  0.05573557,  0.05664382,  0.05402391,\n",
       "        0.05327564,  0.05516944,  0.05387671,  0.05127058,  0.05557804,\n",
       "        0.05650549,  0.05522015,  0.0536099 ,  0.05525165,  0.0542026 ,\n",
       "        0.05769583,  0.05526347,  0.05589556,  0.05345975,  0.05293055,\n",
       "        0.05735862,  0.05384324,  0.05083589,  0.05747332,  0.05549238,\n",
       "        0.05707457,  0.05720059,  0.05931543,  0.05353753,  0.05557754])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha @ linear_K(train_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.495"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = SVM_predict(train_X, test_X, alpha)\n",
    "get_precision(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.00416666666667\n"
     ]
    }
   ],
   "source": [
    "print(np.min(alpha))\n",
    "print(np.max(alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, train_y, test_seq, test_y, valid_X, valid_y = split_train_test_valid(DATA[0]['seq_train'], DATA[0]['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, valid_X, valid_y = split_train_test_valid(DATA[0]['X_train'], DATA[0]['y_train'])\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrum_kernel import transform_to_index_and_save, get_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_k(k):\n",
    "    data = {}\n",
    "    for index in range(3):\n",
    "        X_train = np.loadtxt('spectral_preindexed/Xtr%s_spectral_%s.gz' % (index, k))\n",
    "        seq_train = pd.read_csv('Xtr%s.csv' % index, names='1').values\n",
    "        X_test = np.loadtxt('spectral_preindexed/Xte%s_spectral_%s.gz' % (index, k))\n",
    "        seq_test = pd.read_csv('Xte%s.csv' % index, names='1').values\n",
    "        labels = pd.read_csv('Ytr%s.csv' % index, names=('Id', 'Bound'), skiprows=[0], delimiter=',')\n",
    "\n",
    "        X_train_mean = X_train.mean(axis=0)\n",
    "        X_train_center = X_train - X_train_mean\n",
    "        X_test_center = X_test - X_train_mean\n",
    "        \n",
    "        data[index] = {\n",
    "            'seq_train': seq_train,\n",
    "            'X_train': X_train,\n",
    "            'y_train': labels['Bound'].values,\n",
    "            'seq_test': seq_test,\n",
    "            'X_test': X_test,\n",
    "            'ids': labels['Id'].values,\n",
    "        }\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "def spectrum_2(word1, word2):\n",
    "    return sum(word2.count(word1[i:i+k]) for i in range(len(word1)-k+1))\n",
    "\n",
    "def spectrum_kernel_2(seq1, seq2):\n",
    "    n1 = seq1.shape[0]\n",
    "    n2 = seq2.shape[0]\n",
    "\n",
    "    K = np.zeros((n1,n2))\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            K[i,j] = spectrum_2(seq1[i,0], seq2[j,0])\n",
    "    \n",
    "    return K\n",
    "\n",
    "K = spectrum_kernel_2(train_seq, train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(K[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_kernel(x1, x2):        \n",
    "    return x1 @ x2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = spectrum_kernel(train_X, train_X)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_PARAMS_SPAN = [10**i for i in range(-5, 5)] + [10**i/2 for i in range(-5, 5)]\n",
    "\n",
    "def get_best_reg_param(train_X, train_y, test_X, test_y):\n",
    "    test_precisions = []\n",
    "    for reg in REG_PARAMS_SPAN:\n",
    "        alpha = kernel_ridge_regression(spectrum_kernel, train_X, train_y, reg)\n",
    "        pred = get_ridge_prediction(spectrum_kernel, train_X, test_X, alpha)\n",
    "        test_precisions.append(get_precision(pred, test_y))\n",
    "        \n",
    "    best_reg_index = max(range(len(REG_PARAMS_SPAN)), key=lambda x: test_precisions[x])\n",
    "    return REG_PARAMS_SPAN[best_reg_index], test_precisions[best_reg_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_reg_param(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatch Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = load_data_k(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, valid_X, valid_y = split_train_test_valid(DATA[0]['X_train'], DATA[0]['y_train'])\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mismatch_matrix(k,m):\n",
    "    words = get_words(k)\n",
    "    mismatch_matrix = np.zeros((len(words), len(words)))\n",
    "    for i in range(len(words)):\n",
    "        for j in range(i, len(words)):\n",
    "            if Levenshtein.hamming(words[i], words[j]) <= m:\n",
    "                mismatch_matrix[i,j] = 1/2\n",
    "                mismatch_matrix[j,i] = 1/2\n",
    "    return mismatch_matrix\n",
    "\n",
    "mismatch_matrix = get_mismatch_matrix(6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mismatch_kernel(x1, x2):\n",
    "    return x1 @ mismatch_matrix @ x2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = mismatch_kernel(train_X, train_X)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_PARAMS_SPAN = [10**i for i in range(-10, 10)] + [10**i/2 for i in range(-10, 10)]\n",
    "\n",
    "def get_best_reg_param(train_X, train_y, test_X, test_y):\n",
    "    test_precisions = []\n",
    "    K_train = mismatch_kernel(train_X, train_X)\n",
    "    K_test = mismatch_kernel(train_X, test_X)\n",
    "    for reg in REG_PARAMS_SPAN:\n",
    "        alpha = kernel_ridge_regression(mismatch_kernel, train_X, train_y, reg, K=K_train)\n",
    "        pred = get_ridge_prediction(mismatch_kernel, train_X, test_X, alpha, K_x=K_test)\n",
    "        test_precisions.append(get_precision(pred, test_y))\n",
    "        \n",
    "    best_reg_index = max(range(len(REG_PARAMS_SPAN)), key=lambda x: test_precisions[x])\n",
    "    return REG_PARAMS_SPAN[best_reg_index], test_precisions[best_reg_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_reg_param(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homemade mismatch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_mismatch_matrix(k, _lambda):\n",
    "    words = get_words(k)\n",
    "    exp_mismatch_matrix = np.zeros((len(words), len(words)))\n",
    "    for i in range(len(words)):\n",
    "        exp_mismatch_matrix[i,i] = 1\n",
    "        for j in range(i+1, len(words)):\n",
    "            exp_mismatch_matrix[i,j] = _lambda**Levenshtein.hamming(words[i], words[j])\n",
    "            exp_mismatch_matrix[j,i] = exp_mismatch_matrix[i,j]\n",
    "            \n",
    "    return exp_mismatch_matrix\n",
    "\n",
    "exp_mismatch_matrix = get_exp_mismatch_matrix(6,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mismatch_matrix[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_mismatch_kernel(x1, x2):\n",
    "    return x1 @ exp_mismatch_matrix @ x2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = exp_mismatch_kernel(train_X, train_X)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_PARAMS_SPAN = [10**i for i in range(0, 10)]\n",
    "LAMBDA_SPAN = [0.5, 0.1, 0.05, 0.01]\n",
    "\n",
    "def get_best_reg_param(train_X, train_y, test_X, test_y):\n",
    "    test_precisions = []\n",
    "    K_train = mismatch_kernel(train_X, train_X)\n",
    "    K_test = mismatch_kernel(train_X, test_X)\n",
    "\n",
    "    for reg in REG_PARAMS_SPAN:\n",
    "        alpha = kernel_ridge_regression(mismatch_kernel, train_X, train_y, reg, K=K_train)\n",
    "        pred = get_ridge_prediction(mismatch_kernel, train_X, test_X, alpha, K_x=K_test)\n",
    "        test_precisions.append(get_precision(pred, test_y))\n",
    "\n",
    "    best_reg_index = max(range(len(REG_PARAMS_SPAN)), key=lambda x: test_precisions[x])\n",
    "        \n",
    "    return REG_PARAMS_SPAN[best_reg_index], test_precisions[best_reg_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_reg_param(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substring Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, valid_X, valid_y = split_train_test_valid(DATA[0]['seq_train'], DATA[0]['y_train'])\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from substring_kernel import K_k, substring_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 0.1\n",
    "K_k(LAMBDA, 2, 'car', 'car') - 2*LAMBDA**4+LAMBDA**6 < 10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_k(0.1, 5, \n",
    "   'CAGCTTTTATCACCTTTGAGGGAAAGTCATATTAATTTAATACTGCACACACTTGTACAACAGATCTTCTTTACTATTAAAACTCAGTTTATCAAATCACA',\n",
    "   'AATAACATACCCCACTCTTTCATCTCAATCAAAAATTGAAAAAGTCAAAGAATCCTGCTTTTTTGTTTTTCTCCAAGCCATTACCCCCTCTTGATCATTGC'\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is too slow by several orders of magnitude...\n",
    "for j in range(train_X.shape[0]):\n",
    "    print(j)\n",
    "    K_k(0.1, 2, train_X[1,0], train_X[j,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = load_data_k(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[0]['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_results(preds, ids):\n",
    "    data = [\n",
    "        '%s,%s' % (id, pred) for pred, id in zip(preds, ids)\n",
    "    ]\n",
    "    \n",
    "    data.insert(0, 'Id,Bound')\n",
    "    with open('submission.csv', 'w') as f:\n",
    "        f.write('\\n'.join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune_and_pred_on_test():\n",
    "    preds = []\n",
    "    ids = []\n",
    "    for index in range(3):\n",
    "        train_X, train_y, test_X, test_y, valid_X, valid_y = split_train_test_valid(\n",
    "            DATA[index]['X_train'], \n",
    "            DATA[index]['y_train']\n",
    "        )\n",
    "\n",
    "        # Finding best parameter\n",
    "        reg_param, _ = get_best_reg_param(train_X, train_y, test_X, test_y)\n",
    "\n",
    "        # Validation precision\n",
    "        alpha = kernel_ridge_regression(spectrum_kernel, train_X, train_y, reg_param)\n",
    "        pred = get_ridge_prediction(spectrum_kernel, train_X, valid_X, alpha)\n",
    "        print(\"Dataset %s has found a parameter (%s) with validation precision %.3f\" % (index, reg_param, get_precision(pred, valid_y)))\n",
    "        \n",
    "        continue\n",
    "        # Kaggle submission\n",
    "        alpha = kernel_ridge_regression(exp_mismatch_kernel, DATA[index]['X_train'], DATA[index]['y_train'], reg_param)\n",
    "        pred = get_ridge_prediction(exp_mismatch_kernel, DATA[index]['X_train'], DATA[index]['X_test'], alpha)\n",
    "        \n",
    "        preds += list(pred)\n",
    "\n",
    "    produce_results(preds, range(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_and_pred_on_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_variability(reg_params, N=20):\n",
    "    results = np.zeros((3,N))\n",
    "    for index in range(3):\n",
    "        print(index)\n",
    "        for n in range(N):\n",
    "            train_X, train_y, test_X, test_y, valid_X, valid_y = split_train_test_valid(\n",
    "                DATA[index]['X_train'], \n",
    "                DATA[index]['y_train']\n",
    "            )\n",
    "            \n",
    "            # Validation precision\n",
    "            alpha = kernel_ridge_regression(spectrum_kernel, train_X, train_y, reg_params[index])\n",
    "            pred = get_ridge_prediction(spectrum_kernel, train_X, valid_X, alpha)\n",
    "            results[index,n] = get_precision(pred, valid_y)\n",
    "    return results\n",
    "\n",
    "res = see_variability(reg_params=[1000,500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(res.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
